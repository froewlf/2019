### 京东复盘

#### 1、项目中有用到分库分表了么？
* 解决问题：数据库分表可以解决单表海量数据的查询性能问题，分库可以解决单台数据库的并发访问压力的问题。
* 应用场景：在没分库分表情况下当订单表数量超过1000w条以上，我们需要对订单表按照业务进行分库分表（当超过500w条数据库查询用索引效率大大下降）
* 技术方案：一般都采用第三方工具，当当网的sharding-jdbc、阿里TDDL、mycat和Cobar的插件
  * 数据分表实现策略：一般采用业务进行分，比如订单表，如果是用户订单那么按照用户id后两位（当数据量不是很大情况下）取模存到不同的数据库表中
* 数据库环境：一般采用一个主机（或者多个），安装多个数据库，设置不同数据库端口
* 主从复制：一般采用主从复制，新增和修都在主库，查询都是在从库中，一般一对多。
* 规则：既然分库分表就不要join查询
* 重点
  * 一般会员id使用UUID，那么首先要进行hash获取到整数值，然后进行取模操作
  * 所有数据根据数据库表量进行取模
  * 必须对数据库查询关键字段添加索引，提高查询效率


#### 2、项目中的难点是什么？

* 

#### 3、项目中都有什么场景用到并发？



#### 4、项目中什么地方用到了线程池？

* 定时任务处理时，会用到线程池

#### 5、让你自己设计一个线程池，怎么做？

* 首先定义一个worker，worker中存放线程、和线程要执行的任务（Runnable）
* 在创建一个hashSet存放worker，并设置初始容量
* 在创建一个阻塞队列，当hashSet放满后，存放要执行的任务
* 创建一个executer方法
  * 先判断hashSet是否存满，没有存满，创建worker并开启线程执行任务
    * 执行完成当前任务后，会去队列里获取等待执行的任务，并执行，直到队列里任务全部执行完成，或清空
  * 如果set已满，将任务放入队列中，等待执行

#### 6、项目中常用的集合工具有哪些？



#### 7、什么是内存模型？

* 线程的工作内存和主内存的变量交互的
* volatile 
  * 可见性
  * 防止重排

#### 8、config 高可用怎么实现的？

* 将config服务注册到eureka服务上，实现高可用

#### 9、redis分布式锁实现原理



#### 10、redis主宕机了怎么处理？

* 首先要确认是否做持久化，若没有持久化，重新启动主的reids就会造成数据丢失
  * 先把从的redis升级为主的redis，执行slave of no one命令
  * 将原来的主重启后，作为从redis，连接到主的redis上
  * 主要，主宕机后，需要判断主从数据是否一致，如果不一致需要将不一致的部分增量添加到从，再将从升级为主

* 哨兵机制
  * 哨兵们检测到主宕机后，会首先进行选主操作，n/2+1（过半原则）
  * 哨兵会通过一定的算法，选取一个和主redis数据相近的从（数据偏移量最大的从），升级为主

#### 11、redis 存放的key对应的value值非常大，怎么存放？

* 可以尝试将对象分拆成几个key-value，使用multiGet获取值，这样分拆的意义在于分拆单词操作的压力，将操作压力平摊到多个redis实例中，降低对单个redis的IO影响
* 也可以将这个存储在一个hash中，每个field代表一个具体的属性，使用hget、hmget来获取部分value，使用hset、hmset来更新部分属性

<https://blog.csdn.net/huxianbo0807/article/details/102912172>

#### 12、netty有了解么？



#### 13、使用mq过程中都遇到过什么问题？

* 消息被重复消费
  * 消费端接口幂等处理
* 消息丢失
  * 绑定的key错误
* 主宕机，消息没有持久化
  * 可以引入RabbitMQ的镜像队列机制，相当于配置了副本，如果主节点在数据没有来的急持久化时宕机，可以自动切换到从节点，这样有效的保证了高可用
* 内存溢出
  * 队列中一次性存放的消息过多，可以设置队列中存放待处理消息的个数

#### 14、分布式事务

* 强一致
  * 建立事务表
* 最终一致
  * 使用消息队列或消息表

#### 15、数据库事务怎么管理的，底层实现是什么？

* 使用spring 注解@Transaction来管理实务，底层是通过SpringAOP来实现的  TransactionInterceptor（事务拦截器）
* 通过动态代理在执行方法前后，增加切面，实现事务开启、提交

#### 16、一个文件超过了内存的大小，怎么读取？

* 在Linux下可以通过split方法将大文件切割成很多小文件，然后分别进行读取。
* 文件流
  * 使用Java.util.Scanner类扫描文件的内容，一行一行的读取
* Apache Commons IO流
  * 逐行读取


#### 17、什么是AQS？

